# Universal Representations
This is the implementation of [Universal Representations: A Unified Look at Multiple Task and Domain Learning](https://arxiv.org/pdf/2204.02744.pdf) introduced by [Wei-Hong Li](https://weihonglee.github.io), [Xialei Liu](https://mmcheng.net/xliu/), and [Hakan Bilen](http://homepages.inf.ed.ac.uk/hbilen).

## Updates
* April'22, The preprint of our paper is now available! Code will be available soon! One can refer to [URL](https://github.com/VICO-UoE/URL) for implementation on Cross-domain Few-shot Learning.

## Our Method for Universal Representation Learning
<div>
<p align="center">
  <img src="./figures/apps.png" style="width:100%">
</p>
<p align="adjust">
    Figure 1. We propose a <b>Universal Representation Learning</b> framework in (a) that generalizes over multi-task dense prediction tasks (b), multi-domain many-shot learning (c), cross-domain few-shot learning (d).
</p>
</div>

## Citation
If you use this code, please cite our papers:
```
@article{li2022Universal,
    author    = {Li, Wei-Hong and Liu, Xialei and Bilen, Hakan},
    title     = {Universal Representations: A Unified Look at Multiple Task and Domain Learning},
    journal   = {arXiv preprint arXiv:2204.02744},
    year      = {2022}
}

@inproceedings{li2021Universal,
    author    = {Li, Wei-Hong and Liu, Xialei and Bilen, Hakan},
    title     = {Universal Representation Learning From Multiple Domains for Few-Shot Classification},
    booktitle = {IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {9526-9535}
}

@inproceedings{li2020knowledge,
    author    = {Li, Wei-Hong and Bilen, Hakan},
    title     = {Knowledge distillation for multi-task learning},
    booktitle = {European Conference on Computer Vision (ECCV) Workshop},
    year      = {2020},
    xcode     = {https://github.com/VICO-UoE/KD4MTL}
}
```